{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16. Natural Language Processing with RNNs and Attention.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpSf43Sfv63BLnIJDn/6v3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Shakespearean Text Using a Character RNN"
      ],
      "metadata": {
        "id": "lluO0-MKIeT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a famous [2015 blog post](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) titled “The Unreasonable Effectiveness of Recurrent Neural Networks,” Andrej Karpathy showed how to train an RNN to predict the next character in a sentence\n",
        "\n",
        "This **Char-RNN** can then be used to generate novel text, one character at a time"
      ],
      "metadata": {
        "id": "JfPF18pCIg-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Training Dataset"
      ],
      "metadata": {
        "id": "rz_zpqHTJCnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let’s download all of Shakespeare’s work, using Keras’s handy get_file() function and downloading the data from Andrej Karpathy’ [Char-RNN project](https://github.com/karpathy/char-rnn):"
      ],
      "metadata": {
        "id": "XlIC-lcqJJJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras"
      ],
      "metadata": {
        "id": "sX6rM0CXJo8q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "B5TpAbqIHx2O"
      },
      "outputs": [],
      "source": [
        "shakespeare_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "filepath = keras.utils.get_file('shakespeare.txt', shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "  shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we must encode every character as an integer. One option is to create a custom preprocessing layer, as we did in Chapter 13\n",
        "\n",
        "But in this case, it will be simpler to use Keras’ Tokenizer class. First we need to fit a **tokenizer** to the text: **it will find all the characters used in the text and map each of them to a different character ID, from 1 to the number of distinct characters** (it does not start at 0, so we can use that value for masking, as we will see later in this chapter):"
      ],
      "metadata": {
        "id": "528552bvJ1q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts([shakespeare_text])"
      ],
      "metadata": {
        "id": "lNPR-xC2KWTK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set **char_level=True** to get **character-level encoding rather than the default word-level encoding**. Note that this **tokenizer converts the text to lowercase by default** (but you can set lower=False if you do not want that)\n",
        "\n",
        "Now the tokenizer can encode a sentence (or a list of sentences) to a list of character IDs and back, and it tells us how many distinct characters there are and the total number of characters in the text:"
      ],
      "metadata": {
        "id": "4OWS860MKqEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences([\"First\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj0hOHSmKpnt",
        "outputId": "47eb2ce1-e352-43a6-db82-ea5518d4c730"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 6, 9, 8, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PpVqeHfLgP1",
        "outputId": "aaf4f075-7ad4-42e1-ebbe-43e5370f007c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_id = len(tokenizer.word_index) # number of distinct characters\n",
        "max_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Da8bub2Lo41",
        "outputId": "b765a2b5-303d-4e8f-d079-2fc47d6537ac"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = tokenizer.document_count\n",
        "dataset_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asqyxRV5LwfL",
        "outputId": "4b8443b4-65b7-44d8-9107-9e52326382df"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}